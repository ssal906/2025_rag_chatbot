import streamlit as st
import base64
import pickle
import os
#from dotenv import load_dotenv

from langchain_openai import OpenAIEmbeddings, ChatOpenAI
from langchain_community.vectorstores import FAISS
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain.chains.combine_documents import create_stuff_documents_chain
from langchain.chains import create_retrieval_chain
from langchain_core.runnables.history import RunnableWithMessageHistory
from langchain_community.chat_message_histories.streamlit import StreamlitChatMessageHistory


# âœ… í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ë¯¼ë²• ìƒë‹´ ì±—ë´‡", layout="centered")

st.markdown("""
<style>
body, p, div, span, h1, h2, h3, h4, h5, h6, label, textarea {
    font-family: 'Nanum Myeongjo', 'Gowun Batang', serif !important;
    color: #FFFFFF !important;
}


div[data-baseweb="select"] > div {
    background-color: #626F47 !important;
    color: white !important;
    border-radius: 20px !important;
    border: none !important;           
    box-shadow: none !important;       
}

li[role="option"] {
    background-color: #27391C !important;
    color: black !important;
}

/* ì‚¬ì´ë“œë°” */
section[data-testid="stSidebar"] > div:first-child {
    background-color: #18230F !important;
}


/* ë©€í‹°ë¼ì¸ ì…ë ¥ */
textarea {
    background-color: #555555 !important;
    color: white !important;
}

/* ì‚¬ìš©ì ë§í’ì„  */
.chat-bubble-human {
    background-color: #789DBC;
    border-radius: 12px;
    padding: 14px 18px;
    margin-bottom: 1rem;
    color: #F0F0F0;
    max-width: 65%;
    margin-left: auto;
}

/* AI ë§í’ì„  */
.chat-bubble-ai {
    background-color: #254D70;
    border-radius: 12px;
    padding: 14px 18px;
    margin-bottom: 1rem;
    color: #111827;
    max-width: 65%;
}
</style>
""", unsafe_allow_html=True)


# âœ… ì œëª©
st.title("ë¯¼ë²• ìƒë‹´ ì±—ë´‡")

# âœ… í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
#load_dotenv()
os.environ["OPENAI_API_KEY"] = st.secrets['OPENAI_API_KEY']

import requests

def download_file_from_drive(file_id: str, save_path: str):
    """Google Driveì—ì„œ íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."""
    url = f"https://drive.google.com/uc?export=download&id={file_id}"
    response = requests.get(url)
    os.makedirs(os.path.dirname(save_path), exist_ok=True)
    with open(save_path, "wb") as f:
        f.write(response.content)
    st.success(f"âœ… {os.path.basename(save_path)} ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")

# âœ… ë‹¤ìš´ë¡œë“œ ëŒ€ìƒ ëª©ë¡ (ì˜ˆì‹œ)
files_to_download = {
    "pdf_documents.pkl": "15o-tCm2g-CyFN-VRNpUFc57hfOsvAHYg",
    "pdf_embeddings.pkl": "1JNHnhQdydc74Nb0N1iyWSkzbWiF2U8mb",
    "ê³ ì†Œì¥_documents.pkl": "1FAGxnRHdnp1byu83HIIrOshIa_yhm24m",
    "ê³ ì†Œì¥_embeddings.pkl": "1A8RURLc1MNa4wQbkQGy_fysfR8tOX7ja",
    "ê³„ì•½_documents.pkl" : "1jSOlWeigzOFhBdTf3bKHbmAA9Vf1XzMi",
    "ê³„ì•½_embeddings.pkl" : "1wXRpI9nsa9zzb60wZ8xqrMeQ-MKYq5ao",
    "êµí†µ(ìë™ì°¨)_documents.pkl" : "13LiyWLI_lYYc0Fd6R0bVzww7i7ETfJ3d",
    "êµí†µ(ìë™ì°¨)_embeddings.pkl" : "1OBqMxzVIYSgj1hXEwPPLcEamj3ybykUn",
    "ê¸°íƒ€_documents.pkl" : "17GDNfaCYei9218LM2hS7OzaEaaL7O-_D",
    "ê¸°íƒ€_embeddings.pkl" : "1GTKpR8ZvEa-dePD_rtnzVxJxvIAMnOfl",
    "ë…¸ë™_documents.pkl" : "1AhhiJQSWuFQB6EUYPsYjvklt4FuNTvyx",
    "ë…¸ë™_embeddings.pkl" : "1wQHEUqR0gzTk6cel-4qu2B8BPCZgQ76o",
    "ëŒ€ê¸ˆ_documents.pkl" : "1s3sntC64PPr6enojAWgNSCdi6WEjJ7MM",
    "ëŒ€ê¸ˆ_embeddings.pkl" : "1xg-muxmIaq668YHzy6zmojhmKFiK5JOX",
    "ë¶€ë™ì‚°_documents.pkl" : "16Ms2bgGhmUnCTHymCqUL0aLh8I1g5igX",
    "ë¶€ë™ì‚°_embeddings.pkl" : "1OxWUcwj3qDXmJbp3p626P82i1_4uehD3",
    "ì‚¬ê¸° ë° í˜•ì‚¬_documents.pkl" : "1YAbXEGuaXjtn1fvHwOM7BKhU3QN8gO5M",
    "ì‚¬ê¸° ë° í˜•ì‚¬_embeddings.pkl" : "1LCc4OoTBBSxTcA7tUFG34V6LL47ltgRT",
    "ìƒì†_documents.pkl" : "1c1kEpXG5u-5uA217ELvgFUfOOpmgp6CE",
    "ìƒì†_embeddings.pkl" : "1cYYxp8UiaMBcV0DFbr3dnNKGeJuJRjZx",
    "ì†í•´ë°°ìƒ_documents.pkl" : "1k_Fd6Hoag1RDRvp5Vc_yOXPWq3gzDXip",
    "ì†í•´ë°°ìƒ_embeddings.pkl" : "1v4B65q6gdyk-PVNlDoIRdjIf0ipFySH4",
    "í•©ì˜ì„œ_documents.pkl" : "12MpaJYWMx1rRm5f5l3H0uZapY2HM8ihz",
    "í•©ì˜ì„œ_embeddings.pkl" : "1yOV9v-uy31t4r10Qbv0dXLZC9stdpIcU"
}

# âœ… íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ í›„ ë‹¤ìš´ë¡œë“œ
for filename, file_id in files_to_download.items():
    local_path = os.path.join("precomputed", filename)
    if not os.path.exists(local_path):
        st.info(f"ğŸ“¥ {filename} ë‹¤ìš´ë¡œë“œ ì¤‘...")
        download_file_from_drive(file_id, local_path)



BASE_DIR="precomputed"





# âœ… ë°°ê²½ ì´ë¯¸ì§€ ì‚½ì… í•¨ìˆ˜
def add_bg_from_local(image_path):
    with open(image_path, "rb") as img_file:
        encoded = base64.b64encode(img_file.read()).decode()
    st.markdown(f"""
    <style>
    html, body, [class*="css"] {{
        font-family: 'Nanum Myeongjo', 'Gowun Batang', serif;
        color: #000000 !important;
    }}
    .stApp {{
        background-image: url("data:image/jpg;base64,{encoded}");
        background-size: cover;
        background-attachment: fixed;
        background-position: center;
    }}
 </style>
    """, unsafe_allow_html=True)

def render_example_block(text: str):
    styled_html = f"""
    <div style="
        background-color: #254D70;
        color: white;
        padding: 20px;
        border-radius: 10px;
        font-size: 16px;
        font-family: 'Nanum Myeongjo', 'Gowun Batang', serif;
        white-space: pre-wrap;
        ">
        {text}
    </div>
    """
    st.markdown(styled_html, unsafe_allow_html=True)

        
def contains_legal_example(text: str):
    example_keywords = ["ê³ ì†Œì¥", "í•©ì˜ì„œ", "ê³„ì•½ì„œ", "ì˜ˆì‹œ:", "ê³    ì†Œ   ì¥", "í•©   ì˜   ì„œ"]
    return any(keyword in text for keyword in example_keywords)


# âœ… ë°°ê²½ ì´ë¯¸ì§€ ê²½ë¡œ ì„¤ì •
add_bg_from_local("background.jpg")

# âœ… ì‚¬ì´ë“œë°” ë©”ë‰´
st.sidebar.title("ğŸ”§ ë©”ë‰´")
menu_option = st.sidebar.radio("í˜ì´ì§€ ì„ íƒ", ["ğŸ¤– ì±—ë´‡", "ğŸ“˜ í”„ë¡œì íŠ¸ ì†Œê°œ"])

# âœ… ì„¤ì •


CATEGORIES = [
    "ìƒë‹´ ë¶„ë¥˜ë¥¼ ì§€ì •í•´ì£¼ì„¸ìš”", "ê³ ì†Œì¥", "í•©ì˜ì„œ", 
    "êµí†µ(ìë™ì°¨)", "ì‚¬ê¸° ë° í˜•ì‚¬", "ë¶€ë™ì‚°", "ë…¸ë™", "ëŒ€ê¸ˆ", "ì†í•´ë°°ìƒ", "ìƒì†", "ê³„ì•½", "ê¸°íƒ€"
]



def find_pkl_file(category_name, file_type):
    filename = f"{category_name}_{file_type}.pkl"
    full_path = os.path.join(BASE_DIR, filename)
    return full_path if os.path.exists(full_path) else None



def find_pdf_pkl(file_type):
    filename = f"pdf_{file_type}.pkl"
    full_path = os.path.join(BASE_DIR, filename)
    return full_path if os.path.exists(full_path) else None

@st.cache_resource
def load_embeddings(category):
    pdf_docs, pdf_vecs = [], []
    pdf_doc_path = find_pdf_pkl("documents")
    pdf_vec_path = find_pdf_pkl("embeddings")
    if pdf_doc_path and pdf_vec_path:
        with open(pdf_doc_path, "rb") as f:
            pdf_docs = pickle.load(f)
        with open(pdf_vec_path, "rb") as f:
            pdf_vecs = pickle.load(f)
            
    cat_docs, cat_vecs = [], []
    if category and category != "ìƒë‹´ ë¶„ë¥˜ë¥¼ ì§€ì •í•´ì£¼ì„¸ìš”":
        cat_doc_path = find_pkl_file(category, "documents")
        cat_vec_path = find_pkl_file(category, "embeddings")
        if cat_doc_path and cat_vec_path:
            with open(cat_doc_path, "rb") as f:
                cat_docs = pickle.load(f)
            with open(cat_vec_path, "rb") as f:
                cat_vecs = pickle.load(f)
                
    # ë””ë²„ê¹…ìš© ì¶œë ¥
    st.write(f"PDF ë¬¸ì„œ/ì„ë² ë”©: {len(pdf_docs)}/{len(pdf_vecs)}")
    st.write(f"ì¹´í…Œê³ ë¦¬ ë¬¸ì„œ/ì„ë² ë”©: {len(cat_docs)}/{len(cat_vecs)}")

    # ë°ì´í„° ì—†ìœ¼ë©´ ì•ˆë‚´
    if (len(pdf_docs) == 0 or len(pdf_vecs) == 0) and (len(cat_docs) == 0 or len(cat_vecs) == 0):
        st.warning("pkl íŒŒì¼ì´ ì—†ê±°ë‚˜, ë°ì´í„°ê°€ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
    return pdf_docs, pdf_vecs, cat_docs, cat_vecs

from langchain_core.documents import Document

def build_vectorstore(_pdf_docs, _pdf_vecs, _cat_docs, _cat_vecs, category):
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")

    cat_docs_wrapped = [
        Document(page_content=doc) if isinstance(doc, str) else doc
        for doc in _cat_docs
    ]
    cat_pairs = [(doc.page_content, vec) for doc, vec in zip(cat_docs_wrapped, _cat_vecs)]

    pdf_docs_wrapped = [
        Document(page_content=doc) if isinstance(doc, str) else doc
        for doc in _pdf_docs
    ]
    pdf_pairs = [(doc.page_content, vec) for doc, vec in zip(pdf_docs_wrapped, _pdf_vecs)]

    st.write(f"ğŸ“„ ë²¡í„°ìŠ¤í† ì–´ êµ¬ì„± ì¤‘ - PDF {len(pdf_pairs)}, CAT {len(cat_pairs)}")

    vectorstore = FAISS.from_embeddings(pdf_pairs + cat_pairs, embeddings)
    return vectorstore




@st.cache_resource
def initialize_rag_chain(model_name, _vectorstore):
    retriever = _vectorstore.as_retriever(search_kwargs={"k": 10})
    qa_prompt = ChatPromptTemplate.from_messages([
    ("system",
     """ë‹¹ì‹ ì€ ëŒ€í•œë¯¼êµ­ ë¯¼ë²•ê³¼ í˜•ì‚¬ë²•, ê¸°íƒ€ ì£¼ìš” ë²•ë¥ ì— ì •í†µí•œ AI ë²•ë¥  ìƒë‹´ ì±—ë´‡ì…ë‹ˆë‹¤.  
     ë‹¤ìŒì˜ ì§€ì¹¨ì— ë”°ë¼ ê³µì†í•˜ê³  ì‹ ë¢°ê° ìˆëŠ” í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”.
     
     ğŸ“˜ [ë²•ë¥  ê°œë… ì„¤ëª…]
     - ì‚¬ìš©ìê°€ ì§ˆë¬¸í•œ ë²•ë¥  ê°œë…ì´ë‚˜ ì¡°í•­ì— ëŒ€í•´ **ì •í™•í•˜ê³  ìì„¸í•˜ê²Œ** ì„¤ëª…í•©ë‹ˆë‹¤.
     - ë°˜ë“œì‹œ ê´€ë ¨ ë²•ë¥  ì¡°ë¬¸ ë²ˆí˜¸ë¥¼ í•¨ê»˜ ì œê³µí•©ë‹ˆë‹¤.  
       ì˜ˆ: "ë¯¼ë²• ì œ750ì¡° (ë¶ˆë²•í–‰ìœ„)", "í˜•ë²• ì œ347ì¡° (ì‚¬ê¸°ì£„)", "ë¯¼ì‚¬ì†Œì†¡ë²• ì œ217ì¡°"

    ğŸ“„ [ê³ ì†Œì¥ ë° í•©ì˜ì„œ ì´ˆì•ˆ ì‘ì„±]
    - ì‚¬ìš©ìê°€ ê³ ì†Œì¥ ë˜ëŠ” í•©ì˜ì„œì˜ ì–‘ì‹ì„ ìš”ì²­í•  ë•Œ, êµ¬ì²´ì ì¸ ì˜ˆì‹œì™€ í•¨ê»˜ ìì„¸í•˜ê²Œ ì–´ë–¤ ì •ë³´ê°€ í•„ìš”í•œì§€ ì„¤ëª…í•©ë‹ˆë‹¤.
    - ì‚¬ìš©ìì˜ ì…ë ¥ì„ ë°”íƒ•ìœ¼ë¡œ **ë¬¸ì„œ ì´ˆì•ˆì„ ìš°ì„  ìƒì„±**í•˜ì„¸ìš”.
    - í•„ìš”í•œ ì •ë³´ê°€ ë¶€ì¡±í•œ ê²½ìš°, ë¨¼ì € ê°€ëŠ¥í•œ ë²”ìœ„ë§Œ ì‘ì„±í•œ ë’¤ **ëˆ„ë½ëœ í•­ëª©ì„ ì •ì¤‘íˆ ìš”ì²­**í•˜ì„¸ìš”.  
      ì˜ˆ: "í”¼ê³ ì¸ì˜ ì´ë¦„ì´ í•„ìš”í•©ë‹ˆë‹¤", "ì‚¬ê±´ ë°œìƒ ì¼ìë¥¼ ì•Œë ¤ì£¼ì„¸ìš”"
    - ê³ ì†Œì¥ê³¼ í•©ì˜ì„œì— ë“¤ì–´ê°ˆ ê¸°ë³¸ í•­ëª©ë“¤ì„ í•¨ê»˜ ì•ˆë‚´í•©ë‹ˆë‹¤.  
      ì˜ˆ: ì‚¬ê±´ ê°œìš”, ë‹¹ì‚¬ì ì •ë³´, ì²­êµ¬ ë‚´ìš© ë“±

    ğŸ“Œ [íŒê²° ì˜ˆì¸¡ ì›ì¹™]
    - ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ **êµ¬ì²´ì ì¸ ìƒí™©**(ex. ì‹ í˜¸ìœ„ë°˜, í”¼í•´ì ê²½ìƒ ë“±)ì„ í¬í•¨í•  ê²½ìš°:
      â†’ **ê°€ì • ì—†ì´**, í•´ë‹¹ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ê´€ë ¨ ë²•, ì¼ë°˜ì  íŒê²°, ì˜ˆìƒ ì²˜ë²Œ ìˆ˜ìœ„(ë²Œê¸ˆ, ë©´í—ˆì •ì§€ ë“±)ë¥¼ ë°˜ë“œì‹œ ì œì‹œí•©ë‹ˆë‹¤.
      â†’ ì˜ˆ: "ë²Œê¸ˆ 300~500ë§Œ ì›", "ë©´í—ˆì •ì§€ 30ì¼", "ìœ„ìë£Œ 100~200ë§Œ ì›"

    - ì§ˆë¬¸ì´ **í¬ê´„ì ì´ê±°ë‚˜ ë¶€ì¡±í•  ê²½ìš°**:
      â†’ í˜„ì‹¤ì ì¸ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ ì§ì ‘ ì„¤ì •í•˜ê³  ê°€ì •ì„ ëª…í™•íˆ ì œì‹œí•œ í›„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
      â†’ ì˜ˆ: "ê°€ì •: ê°€í•´ìëŠ” ì‹ í˜¸ìœ„ë°˜ ì´ˆë²”ì´ë©°, í”¼í•´ìëŠ” ì¹˜ë£Œ 2ì£¼ ê²½ìƒì˜ ë¶€ìƒì„ ì…ì—ˆìŠµë‹ˆë‹¤..."
      â†’ ì˜ˆ: "ê°€ì •: ì„ëŒ€ì¸ì´ ê³„ì•½ê¸°ê°„ ì¢…ë£Œ ì „ì— ì¼ë°©ì ìœ¼ë¡œ ê³„ì•½ì„ í•´ì§€í•œ ê²½ìš°..."

    - ì–´ë–¤ ê²½ìš°ì—ë„ **'ì •í™•íˆ ì•Œ ìˆ˜ ì—†ìŠµë‹ˆë‹¤' ë˜ëŠ” 'ë” êµ¬ì²´ì  ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤'** ë¼ëŠ” ë‹µì€ í•˜ì§€ ë§ˆì„¸ìš”.
      â†’ ëŒ€ì‹ , ì¼ë°˜ì ì¸ ì‚¬ë¡€ ê¸°ì¤€ì—ì„œ ì„¤ëª…í•˜ê³  ì˜ˆì¸¡ì„ ì œì‹œí•˜ì„¸ìš”.
    - ë‹µë³€ì—ëŠ” **ì •ëŸ‰ì  ì •ë³´**(ë²Œê¸ˆì•¡, ìœ„ìë£Œ, ë°°ìƒë¹„, í˜•ëŸ‰ ë“±)ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”.


    ğŸ“š [ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€ (RAG)]
    - contextë¡œ ì œê³µëœ ë¬¸ì„œ(íŒê²°ë¬¸, ì‚¬ë¡€, ì¡°ë¬¸ ë“±)ë¥¼ ìµœìš°ì„  ê·¼ê±°ë¡œ ì‚¬ìš©í•˜ì„¸ìš”.
    - ë¬¸ì„œê°€ ì—†ê±°ë‚˜ ë¶€ì¡±í•œ ê²½ìš°ì—ë„ ì¼ë°˜ì ì¸ íŒë¡€ ê²½í–¥ì„ ê·¼ê±°ë¡œ ì‹ ì¤‘íˆ ì„¤ëª…í•©ë‹ˆë‹¤.
    - í™•ì¸ë˜ì§€ ì•Šì€ ì •ë³´ë¥¼ ë‹¨ì •ì ìœ¼ë¡œ ë§í•˜ì§€ ë§ˆì„¸ìš”. ë‹¨, ì¼ë°˜ë¡ ì  íŒë‹¨ì€ íšŒí”¼í•˜ì§€ ë§ê³  ì±…ì„ê° ìˆê²Œ í‘œí˜„í•˜ì„¸ìš”.

    âš ï¸ [ê¸°íƒ€ ì£¼ì˜ì‚¬í•­]
    - ëª¨ë“  ì„¤ëª…ì€ **ê³µì†í•˜ê³  ëª…í™•í•œ ë¬¸ì²´**ë¡œ ì „ë‹¬í•˜ì„¸ìš”.
    - í˜¼ë€ì„ ì¤„ ìˆ˜ ìˆëŠ” ë¶ˆí™•ì‹¤í•œ ì¶”ì¸¡ì€ í”¼í•˜ê³ , í•„ìš”í•œ ê²½ìš° "í•´ë‹¹ ì •ë³´ëŠ” ë¬¸ì„œì— ì—†ìŠµë‹ˆë‹¤"ë¼ê³  ì•ˆë‚´í•˜ì„¸ìš”.
{context}
"""),
    MessagesPlaceholder("chat_history"),
    ("human", "{input}"),
])

    llm = ChatOpenAI(model=model_name)
    qa_chain = create_stuff_documents_chain(llm, qa_prompt)
    rag_chain = create_retrieval_chain(retriever, qa_chain)
    return rag_chain

# âœ… ì±—ë´‡ í˜ì´ì§€
if menu_option == "ğŸ¤– ì±—ë´‡":
    st.title("ğŸ‘©â€âš–ï¸ ë¯¼ë²• ìƒë‹´ ì±—ë´‡")
    st.markdown("##### ì •ì¤‘í•˜ê³  ì‹ ë¢°ê° ìˆëŠ” ë²•ë¥  ìƒë‹´ì„ ì œê³µí•©ë‹ˆë‹¤.")

    model_choice = st.selectbox("GPT ëª¨ë¸ì„ ì„ íƒí•´ì£¼ì„¸ìš”", ("gpt-4o", "gpt-3.5-turbo-0125"))
    category = st.selectbox("ìƒë‹´ ë¶„ë¥˜ë¥¼ ì„ íƒí•˜ì„¸ìš”", CATEGORIES, index=0)

    if category == "ìƒë‹´ ë¶„ë¥˜ë¥¼ ì§€ì •í•´ì£¼ì„¸ìš”":
        st.info("ìƒë‹´ ë¶„ë¥˜ë¥¼ ë¨¼ì € ì„ íƒí•´ ì£¼ì„¸ìš”.")
        st.stop()

    pdf_docs, pdf_vecs, cat_docs, cat_vecs = load_embeddings(category)
    if (not pdf_docs or not pdf_vecs) and (not cat_docs or not cat_vecs):
        st.warning("ì±—ë´‡ì— ì‚¬ìš©í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. pkl íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()

    vectorstore = build_vectorstore(pdf_docs, pdf_vecs, cat_docs, cat_vecs, category)

    rag_chain = initialize_rag_chain(model_name=model_choice, _vectorstore=vectorstore)

    chat_history = StreamlitChatMessageHistory(key="chat_messages")
    conversational_rag_chain = RunnableWithMessageHistory(
        rag_chain,
        lambda session_id: chat_history,
        input_messages_key="input",
        history_messages_key="chat_history",
        output_messages_key="answer",
    )

    if not chat_history.messages:
        chat_history.add_ai_message("ì•ˆë…•í•˜ì„¸ìš”! ë¯¼ë²•ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”.")

    for msg in chat_history.messages:
        if msg.type == "ai":
            st.markdown(f"<div class='chat-bubble-ai'>{msg.content}</div>", unsafe_allow_html=True)
        else:
            st.markdown(f"<div class='chat-bubble-human'>{msg.content}</div>", unsafe_allow_html=True)

    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš” :)"):
        st.markdown(f"<div class='chat-bubble-human'>{prompt}</div>", unsafe_allow_html=True)
        with st.spinner("Thinking..."):
            config = {"configurable": {"session_id": "any"}}
            response = conversational_rag_chain.invoke({"input": prompt}, config)
            answer = response.get("answer", "ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            if contains_legal_example(answer):
                render_example_block(answer)  # ì˜ˆì‹œë‹ˆê¹Œ ê²€ì • ë°°ê²½ ì¶œë ¥
            else:
                st.markdown(f"<div class='chat-bubble-ai'>{answer}</div>", unsafe_allow_html=True)


# âœ… ì†Œê°œ í˜ì´ì§€
elif menu_option == "ğŸ“˜ í”„ë¡œì íŠ¸ ì†Œê°œ":
    st.title("ğŸ“˜ í”„ë¡œì íŠ¸ ì†Œê°œ")
    st.markdown("""
    ### ğŸ‘©â€âš–ï¸ ë¯¼ë²• ìƒë‹´ ì±—ë´‡ í”„ë¡œì íŠ¸
    ì´ í”„ë¡œì íŠ¸ëŠ” ì‚¬ìš©ìê°€ ë¯¼ë²• ê´€ë ¨ ë¬¸ì„œë¥¼ ë³´ë‹¤ ì‰½ê²Œ ì‘ì„±í•˜ê³ ,
    ìì£¼ ë¬»ëŠ” ë²•ë¥  ì§ˆë¬¸ì— ëŒ€í•´ ë„ì›€ì„ ë°›ì„ ìˆ˜ ìˆë„ë¡ ì„¤ê³„ë˜ì—ˆìŠµë‹ˆë‹¤.

    ---
    #### ğŸ“Œ ì£¼ìš” ê¸°ëŠ¥
    - ìì—°ì–´ ê¸°ë°˜ ë¯¼ë²• ìƒë‹´ ì œê³µ
    - ê³ ì†Œì¥, í•©ì˜ì„œ, ê³„ì•½ í•´ì œ ì¡°ê±´ ë“±ì— ëŒ€í•œ ìë™ ì‘ë‹µ
    - Streamlit UIì™€ ì‚¬ìš©ì ì¹œí™”ì  ì¸í„°í˜ì´ìŠ¤

    #### ğŸ›  ê¸°ìˆ  ìŠ¤íƒ
    - Python, Streamlit
    - LangChain + FAISS
    - OpenAI API


    ë¯¼ë²•ì— ëŒ€í•œ ì ‘ê·¼ì„±ê³¼ ì •ë³´ ì „ë‹¬ì„ ê°œì„ í•˜ê¸° ìœ„í•´ ì§€ì†ì ìœ¼ë¡œ ê°œì„ í•´ ë‚˜ê°€ê² ìŠµë‹ˆë‹¤.
    """)
